version: '3.8'

# Production Docker Compose Configuration
# WARNING: This is for reference. Use Kubernetes/ECS for production deployments
# For small-scale production only

services:
  # Rails API Server (Multiple replicas)
  app:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    ports:
      - "3000:3000"
    env_file:
      - .env.production
    environment:
      - RAILS_ENV=production
      - RAILS_LOG_TO_STDOUT=true
      - MALLOC_ARENA_MAX=2  # Reduce memory fragmentation
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - app_storage:/app/storage
      - app_logs:/app/log
      - app_tmp:/app/tmp
    command: bundle exec puma -C config/puma.rb
    networks:
      - todoapp-production
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
    deploy:
      mode: replicated
      replicas: 4  # Multiple instances for high availability
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "10"
        compress: "true"

  # Sidekiq Worker (Background Jobs) - High Priority
  sidekiq-critical:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    env_file:
      - .env.production
    environment:
      - RAILS_ENV=production
      - SIDEKIQ_QUEUES=critical,high
      - SIDEKIQ_CONCURRENCY=10
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - app_storage:/app/storage
      - app_logs:/app/log
    command: bundle exec sidekiq -C config/sidekiq.yml -q critical -q high
    networks:
      - todoapp-production
    restart: always
    deploy:
      mode: replicated
      replicas: 3
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"

  # Sidekiq Worker - Default Priority
  sidekiq-default:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    env_file:
      - .env.production
    environment:
      - RAILS_ENV=production
      - SIDEKIQ_QUEUES=default,low
      - SIDEKIQ_CONCURRENCY=20
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - app_storage:/app/storage
      - app_logs:/app/log
    command: bundle exec sidekiq -C config/sidekiq.yml -q default -q low
    networks:
      - todoapp-production
    restart: always
    deploy:
      mode: replicated
      replicas: 5
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"

  # Sidekiq Worker - Mailers
  sidekiq-mailers:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    env_file:
      - .env.production
    environment:
      - RAILS_ENV=production
      - SIDEKIQ_QUEUES=mailers
      - SIDEKIQ_CONCURRENCY=15
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - app_storage:/app/storage
      - app_logs:/app/log
    command: bundle exec sidekiq -C config/sidekiq.yml -q mailers
    networks:
      - todoapp-production
    restart: always
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"

  # MySQL Database (Primary)
  # NOTE: For production, use managed database service (AWS RDS, etc.)
  db:
    image: mysql:8.0
    env_file:
      - .env.production
    environment:
      MYSQL_ROOT_PASSWORD: ${DATABASE_PASSWORD}
      MYSQL_DATABASE: ${DATABASE_NAME}
      MYSQL_USER: ${DATABASE_USERNAME}
      MYSQL_PASSWORD: ${DATABASE_PASSWORD}
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql
      - mysql_backups:/backups
      - ./docker/mysql/conf.d/production.cnf:/etc/mysql/conf.d/custom.cnf:ro
    networks:
      - todoapp-production
    restart: always
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "${DATABASE_USERNAME}", "-p${DATABASE_PASSWORD}"]
      interval: 15s
      timeout: 10s
      retries: 5
    command:
      - --default-authentication-plugin=mysql_native_password
      - --character-set-server=utf8mb4
      - --collation-server=utf8mb4_unicode_ci
      - --max_connections=500
      - --innodb_buffer_pool_size=4G
      - --innodb_log_file_size=512M
      - --query_cache_size=0
      - --slow_query_log=1
      - --long_query_time=2
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"

  # Redis (Cache)
  redis-cache:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_cache_data:/data
      - ./docker/redis/redis-cache-prod.conf:/usr/local/etc/redis/redis.conf:ro
    networks:
      - todoapp-production
    restart: always
    command: redis-server /usr/local/etc/redis/redis.conf --requirepass ${REDIS_PASSWORD}
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 15s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"

  # Redis (Queue/Sidekiq)
  redis-queue:
    image: redis:7-alpine
    ports:
      - "6380:6379"
    volumes:
      - redis_queue_data:/data
      - ./docker/redis/redis-queue-prod.conf:/usr/local/etc/redis/redis.conf:ro
    networks:
      - todoapp-production
    restart: always
    command: redis-server /usr/local/etc/redis/redis.conf --requirepass ${REDIS_PASSWORD}
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 15s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"

  # Redis (ActionCable)
  redis-cable:
    image: redis:7-alpine
    ports:
      - "6381:6379"
    volumes:
      - redis_cable_data:/data
      - ./docker/redis/redis-cable-prod.conf:/usr/local/etc/redis/redis.conf:ro
    networks:
      - todoapp-production
    restart: always
    command: redis-server /usr/local/etc/redis/redis.conf --requirepass ${REDIS_PASSWORD}
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 15s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"

  # Nginx Load Balancer & Reverse Proxy
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./docker/nginx/production.conf:/etc/nginx/nginx.conf:ro
      - ./docker/nginx/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
      - nginx_cache:/var/cache/nginx
    depends_on:
      - app
    networks:
      - todoapp-production
    restart: always
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '1'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "10"

  # Prometheus (Metrics Collection)
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./docker/prometheus/prometheus-production.yml:/etc/prometheus/prometheus.yml:ro
      - ./docker/prometheus/rules:/etc/prometheus/rules:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=90d'
      - '--web.enable-lifecycle'
    networks:
      - todoapp-production
    restart: always
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G

  # Grafana (Metrics Visualization)
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_SERVER_ROOT_URL=https://monitoring.your-domain.com
      - GF_INSTALL_PLUGINS=redis-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./docker/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
    networks:
      - todoapp-production
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # AlertManager (Alerting)
  alertmanager:
    image: prom/alertmanager:latest
    ports:
      - "9093:9093"
    volumes:
      - ./docker/alertmanager/config.yml:/etc/alertmanager/config.yml:ro
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
    networks:
      - todoapp-production
    restart: always

  # Database Backup Service
  backup:
    image: mysql:8.0
    env_file:
      - .env.production
    environment:
      - MYSQL_HOST=db
      - MYSQL_USER=${DATABASE_USERNAME}
      - MYSQL_PASSWORD=${DATABASE_PASSWORD}
      - MYSQL_DATABASE=${DATABASE_NAME}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - S3_BUCKET=${BACKUP_S3_BUCKET}
    volumes:
      - mysql_backups:/backups
      - ./docker/backup/backup-production.sh:/backup.sh:ro
    command: /bin/bash -c "cron && tail -f /var/log/cron.log"
    depends_on:
      - db
    networks:
      - todoapp-production
    restart: always

volumes:
  mysql_data:
    driver: local
  mysql_backups:
    driver: local
  redis_cache_data:
    driver: local
  redis_queue_data:
    driver: local
  redis_cable_data:
    driver: local
  app_storage:
    driver: local
  app_logs:
    driver: local
  app_tmp:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  alertmanager_data:
    driver: local
  nginx_logs:
    driver: local
  nginx_cache:
    driver: local

networks:
  todoapp-production:
    driver: bridge
    ipam:
      config:
        - subnet: 172.30.0.0/16
